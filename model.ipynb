{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport random\nimport cv2\nimport torch\nimport os\nimport glob\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom torchvision import models\nfrom torch.utils.tensorboard import SummaryWriter\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! wget http://images.cocodataset.org/zips/test2014.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip test2014.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_salt_and_pepper_noise(image, salt_prob=0.002, pepper_prob=0.002):\n     noisy_image = np.copy(image)\n     total_pixels = image.shape[0] * image.shape[1]\n    \n     num_salt = np.ceil(salt_prob * total_pixels)\n     coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape[:2]]\n     noisy_image[coords[0], coords[1], :] = 1\n\n     num_pepper = np.ceil(pepper_prob * total_pixels)\n     coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape[:2]]\n     noisy_image[coords[0], coords[1], :] = 0\n\n     return noisy_image\n\ndef add_poisson_noise(image):\n    vals = len(np.unique(image))\n    vals = 3 ** np.ceil(np.log2(vals))\n    noisy_image = np.random.poisson(image * vals) / float(vals)\n    noisy_image = np.clip(noisy_image, 0, 1)\n    return noisy_image*0.5\n\ndef add_gaussian_noise(image, mean=0, std=0.07):\n    image = image.astype(np.float32)\n    noise = np.random.normal(mean, std, image.shape).astype(np.float32)\n    noisy_image = image + noise\n    noisy_image = np.clip(noisy_image, 0, 1)\n    \n    return noisy_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NoiseImageDataset(Dataset):\n    \n    def __init__(self, image_paths, transform=None):\n        self.image_paths = image_paths\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        target_size = (128,128)\n        image = cv2.resize(image,target_size,interpolation=cv2.INTER_LINEAR)\n        \n        image = image.astype(np.float32) / 255.0\n        \n        noise_image = add_salt_and_pepper_noise(image)\n        noise_image = add_poisson_noise(noise_image)\n        noise_image = add_gaussian_noise(noise_image)\n        \n        image = torch.tensor(image).permute(2, 0, 1)\n        noise_image = torch.tensor(noise_image).permute(2, 0, 1)\n        \n        return  noise_image.to(device) ,image.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_directory = '/kaggle/working/test2014'\nimage_paths = glob.glob(os.path.join(image_directory, '*.jpg'))\ndataset = NoiseImageDataset(image_paths)\ndataloader = DataLoader(dataset, batch_size=8, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing first image of first two batches in dataloader for reference :\nfor index ,(noise,image) in enumerate(dataloader):\n    if index == 0:\n        noise = noise[0].squeeze().permute(1, 2, 0).cpu().numpy()\n        image = image[0].squeeze().permute(1, 2, 0).cpu().numpy()\n\n        noise = (noise * 255).astype(int)\n        image = (image * 255).astype(int)\n        \n        plt.figure(figsize=(80, 20))\n        \n        plt.subplot(1,20,2)\n        plt.title('Noisy Image')\n        plt.imshow(noise, cmap='gray')\n        \n        plt.subplot(1,20,1)\n        plt.title('Ground Truth')\n        plt.imshow(image, cmap='gray')\n\n        plt.show()\n        \n    if index == 1:\n        break;","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n\n        self.encoder1 = self.conv_block(3, 64)\n        self.encoder2 = self.conv_block(64, 128)\n        self.encoder3 = self.conv_block(128, 256)\n\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n        self.decoder3 = self.conv_block(256, 128)\n        \n        self.upconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n        self.decoder2 = self.conv_block(128, 64)\n        \n        self.upconv1 = nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2)\n        self.conv = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n        self.decoder1 = self.conv_block(128, 64)\n\n        self.final_conv = nn.Conv2d(64, 3, kernel_size=1)\n\n    def conv_block(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n\n    def forward(self, x):\n        enc1 = self.encoder1(x)\n        enc2 = self.encoder2(self.pool(enc1))\n        enc3 = self.encoder3(self.pool(enc2))\n\n        dec3 = self.upconv3(enc3)\n        dec3 = self.decoder3(torch.cat([dec3, enc2], dim=1))  # skip connection\n\n        dec2 = self.upconv2(dec3)\n        dec2 = self.decoder2(torch.cat([dec2, enc1], dim=1))  # skip connection\n\n        dec1 = self.upconv1(dec2)\n        dec1 = self.conv(dec1)\n        dec1 = self.decoder1(torch.cat([dec1, enc1], dim=1))  # skip connection\n\n        output = self.final_conv(dec1)\n        return output\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PerceptualLoss(nn.Module):\n    def __init__(self, layer_ids):\n        super(PerceptualLoss, self).__init__()\n        vgg19 = models.vgg19(pretrained=True).features.eval()\n        self.layer_ids = layer_ids\n        self.vgg19 = vgg19\n        for param in self.vgg19.parameters():\n            param.requires_grad = False \n        self.criterion = nn.MSELoss()\n\n    def forward(self, output, target):\n        output_fea = self.get_features(output.float())\n        target_fea = self.get_features(target.float())\n        \n        loss = 0\n        for o_f, t_f in zip(output_fea, target_fea):\n            loss += self.criterion(o_f, t_f)\n        return loss.item()\n    \n    def get_features(self, x):\n        features = []\n        for i, layer in enumerate(self.vgg19):\n            x = layer(x)\n            if i in self.layer_ids:\n                features.append(x)\n        return features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_ids = [3, 8, 17, 26]\npercep_loss = PerceptualLoss(layer_ids).to(device)\nnet = UNet().to(device)\noptimizer = optim.Adam(net.parameters(), lr=(1e-3)/2)\nnum_epochs = 20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch_loss = []\nepoch_n = []\npsnr_e = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def psnr(gt_image, pred_images, max_val=1.0):\n    mse = torch.mean((gt_image - pred_images) ** 2)\n    psnr_val = 10 * torch.log10((max_val ** 2) / mse)\n    return psnr_val","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    net.train()\n    \n    epoch_loss = 0.0\n    psnr_sum = 0.0\n    \n    progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}')\n\n    for image,noise in progress_bar:\n        \n        image = image.to(device)\n        noise = noise.to(device)\n        \n        optimizer.zero_grad()\n\n        with torch.cuda.amp.autocast():\n            output = net(noise)\n            pixel_loss = nn.MSELoss()(output, image)\n            p_loss = percep_loss(output, image)\n            loss = pixel_loss + 0.01 * p_loss\n                \n        loss.backward()\n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        \n        psnr_batch = psnr(image, output)\n        psnr_sum += psnr_batch\n\n    avg_epoch_loss = epoch_loss/len(dataloader)\n    avg_psnr = psnr_sum / len(dataloader)\n    \n    epoch_loss.append(avg_epoch_loss)\n    epoch_n.append(epoch + 1)\n    psnr_e.append(avg_psnr)\n\n    if epoch+1 == 15:\n        torch.save(net.state_dict(),f\"/kaggle/working/15_unet_ploss_vgg19.pth\")\n    \n\n    print(f\"Epoch : {epoch+1} , Loss : {avg_epoch_loss} , PSNR : {avg_psnr}\")\n\ntorch.save(net.state_dict() , \"/kaggle/working/20_unet_ploss_vgg19.pth\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}